import os
import requests
from dotenv import load_dotenv
from openai import OpenAI

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# OpenAI í´ë¼ì´ì–¸íŠ¸
client = OpenAI(api_key=OPENAI_API_KEY)

# ë„¤ì´ë²„ API í—¤ë” ì„¤ì •
headers = {
    "X-Naver-Client-Id": NAVER_CLIENT_ID,
    "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
}

def fetch_naver_results(query: str, category: str):
    """
    ë„¤ì´ë²„ ë¸”ë¡œê·¸, ë‰´ìŠ¤, ì§€ì‹iN ì¤‘ í•˜ë‚˜ë¥¼ categoryë¡œ ë°›ì•„ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜´
    """
    url = f"https://openapi.naver.com/v1/search/{category}.json"
    params = {"query": query, "display": 5}
    try:
        res = requests.get(url, headers=headers, params=params, timeout=5)
        res.raise_for_status()
        return res.json().get("items", [])
    except Exception as e:
        print(f"[ERROR] {category} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

def format_results(items: list, label: str) -> str:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‚¬ëŒì´ ë³´ê¸° ì‰½ê²Œ í¬ë§·íŒ…
    """
    if not items:
        return f"{label} ì—†ìŒ\n"

    result = f"ğŸ“Œ [{label}]\n"
    for item in items:
        title = item.get("title", "").replace("<b>", "").replace("</b>", "")
        desc = item.get("description", "").replace("<b>", "").replace("</b>", "")
        result += f"{title} â€” {desc}\n"
    return result.strip()

def get_external_info(query: str, system_prompt: str, memory) -> str:
    """
    ì™¸ë¶€ ì •ë³´ ê²€ìƒ‰ í†µí•© í•¨ìˆ˜: ë¸”ë¡œê·¸ + ë‰´ìŠ¤ + ì§€ì‹iN
    ê²°ê³¼ ìš”ì•½ì€ OpenAIë¡œ ì²˜ë¦¬
    """
    # ë„¤ì´ë²„ ê²€ìƒ‰
    blog_items = fetch_naver_results(query, "blog")
    news_items = fetch_naver_results(query, "news")
    kin_items = fetch_naver_results(query, "kin")

    # í¬ë§·íŒ…
    combined_text = (
        format_results(news_items, "ë‰´ìŠ¤") + "\n\n" +
        format_results(blog_items, "ë¸”ë¡œê·¸") + "\n\n" +
        format_results(kin_items, "ì§€ì‹iN")
    )

    # ìš”ì•½ í”„ë¡¬í”„íŠ¸
    prompt = f"""

ì‚¬ìš©ì ì§ˆë¬¸: "{query}"

ê²€ìƒ‰ ê²°ê³¼:
{combined_text}

ì•„ë˜ëŠ” ë„¤ì´ë²„ ë‰´ìŠ¤/ë¸”ë¡œê·¸/ì§€ì‹iNì—ì„œ ì°¾ì€ ê²€ìƒ‰ ê²°ê³¼ì•¼.
ì´ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ìµœëŒ€í•œ ì •í™•í•˜ê²Œ, ì¹œêµ¬ì²˜ëŸ¼ ëŒ€ë‹µí•´ì¤˜.
ë§íˆ¬ëŠ” system_promptë¡œ ì„¤ì •ëœ ë°˜ë§/ì¡´ëŒ“ë§ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•´ì•¼ í•´.

ìš”ì•½ë§Œ í•˜ì§€ ë§ê³ , ì‹¤ì œ ë‚´ìš©ì„ ì¸ìš©í•´ì„œ ì„¤ëª…í•˜ê³ ,
ì‚¬ëŒì´ ë§í•˜ë“¯ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì¤˜.


""".strip()

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"[ERROR] ì™¸ë¶€ ì •ë³´ ìš”ì•½ ì‹¤íŒ¨: {e}"